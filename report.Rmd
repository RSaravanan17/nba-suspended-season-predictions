---
title: "The 2019-20 NBA Season: What Could Have Been"
author:
    - Ryan Kohanski
    - Rithvik Saravanan
    - Howard Yong
date: "May 11, 2020"
output: 
  pdf_document:
    extra_dependencies: ["float"]
    fig_caption: yes
indent: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.pos = 'H')
```

```{r libraries, include=FALSE}
library(elo)
library(tidyverse)
library(mosaic)
library(ggplot2)
library(foreach)
library(data.table)
library(magrittr)
library(dplyr)
library(stringr)
library(elo)
library(rvest)
library(lubridate)
library(cluster)
library(FNN)
library(glmnet)
library(knitr)
```

```{r data, include=FALSE}
season2016_2017 = read.csv('./data/nba-scrape-data-2016-2017.csv', header=TRUE)
season2017_2018 = read.csv('./data/nba-scrape-data-2017-2018.csv', header=TRUE)
season2018_2019 = read.csv('./data/nba-scrape-data-2018-2019.csv', header=TRUE)
season2019_2020 = read.csv('./data/nba-scrape-data-2019-2020.csv', header=TRUE)
remaining_games_19_20 <- read.csv('./data/nba-remaining-games-2019-2020.csv', header=TRUE)
player_stats = read.csv('./data/nba_19-20_player_stats.csv', header=TRUE)
```


# Abstract

The COVID-19 pandemic has affected our society in various ways and has changed numerous events on schedule for 2020. One such event that we were looking forward to was the end of the 2019-20 NBA season as well as the 2020 NBA Playoffs. Since a large portion of the 2019-20 NBA regular season games have already been played, we utilized the data collected from these games to run regression prediction models and calculate Elo ratings for each team in order to predict the standings for 2019-20 as well as the matchups and results of the Playoffs and the NBA season awards. Running our analysis by predicting the 7-game playoff series matchups, we predicted that the Western Conference Finals matchup will be between the #1 seed Los Angeles Lakers and the #2 seed Los Angeles Clippers and the Eastern Conference Finals matchup will be between the #1 seed Milwaukee Bucks and the #2 seed Toronto Raptors. **[NEED TO FIX THE MATCHUPS BASED ON BRACKET]** We found that running these simulations predicts the NBA Finals matchup between the Los Angeles Lakers and the Milwaukee Bucks with the Los Angeles Lakers ultimately claiming the Larry O'Brien NBA Championship Trophy. Additionally, we used several types of regression models to best predict end-of-season statistics for every player. We ultimately used a logistic regression model to predict the end-of-season statistics and leaders for each of the major categories and found that our predictions indicate that Giannis Antetokounmpo will claim both the NBA Most Valuable Player (MVP) award as well as the Defensive Player of the Year (DPOY) award. According to our prediction model, this will mark only the third time in NBA history that a player will win MVP and DPOY in the same season with the previous two players being basketball legends Michael Jordan and Hakeem Olajuwon.



# Introduction

Due to the widespread impact of the COVID-19 pandemic throughout the world, almost every company, organization, and public event has canceled or suspended any activities that involve interpersonal contact for the forseeable future. Many of these activities are moving to a virtual format if possible, but several others have been forced to shut down.

As avid sports fans, the absence of the major sporting events during this time has hit us and many others around the world especially hard [1]. Some of the events that we particularly were looking forward to include the NBA, NCAA March Madness tournament, MLB, and the 2020 Summer Olympics.

In our curiosity, we decided to utilize this opportunity to exercise our data science and modeling skills in order to predict what could have been. Specifically, we focused on the NBA and the NBA Playoffs. Since the 2019-20 NBA season was suspended approximately one month prior to the end of the regular season (and the beginning of the Playoffs), we used the 2019-20 season data accumulated from the games played before the suspension to predict how the season and the Playoffs would have ended had everything gone according to schedule.

In this analysis, we will examine data from the 2019-20 NBA season as well as some data from previous NBA seasons in order to draw some meaningful conclusions about the remainder of the 2019-20 NBA season including the final season standings, playoff matchups, championship winner, and season award winners.



# Methods


## Predicting the 2019-20 NBA Season Standings

Since we missed one of the most exciting times of the year (the NBA Playoffs & Finals), we made some predictions on how the rest of the season might have played out using a popular methodology referred to as the Elo ratings system [2]. This tool, created by Hungarian-American physics professor Arpad Elo, was orginally designed to rate chess players, but is now used for all sorts of competitions ranging anywhere from sports to video games. This is a methodology that FiveThirtyEight and many other popular sports analysts take advantage of due to its simplicity and effectiveness [3].

These ratings depend only on the final score of each game as well as where it was played (home-court advantage). In other words, this system is built on a Win/Loss basis. We will be analyzing the 2018-19 NBA Season in its entirety to validate its performance, then we will apply it to the 2019-20 regular season in order to predict the matchups for the Playoffs and the Finals and ultimately the NBA Champions. For this project, we retrieved several types of data sources including game-by-game scores and schedules for several seasons from Basketball-Reference.com [4].


### How does Elo work?

The long-run average for an Elo score in the NBA sits around 1500. An Elo of 1500 means that the teams performance would be normally distrubuted around an average of 1500 with the chance of performing better or worse. For more detail, Figure \ref{fig:elo_chart} (Appendix) shows what an Elo rating tells us about a team and how it can convey the teams overall season record. A higher Elo rating indicates that the team has a high win-loss ratio and is more likely to play deeper into the season.

The formula for Elo below shows how the probability of one team beating another is calculated using the ratings. When Player $A$ competes in a match against Player $B$, Player $A$ has an expected outcome (probability or score) for Team $A$ ($E[A]$) where $R_A$ is the rating for Team $A$ and $R_B$ is the rating for Team $B$. The expected outcome for Team $A$ ($E[A]$) can be calculated by the formula below:

$$
E[A] = \frac{1}{1 + 10^{\frac{(R_B-R_A)}{400}}}
$$

The same calculation ($E[B]$) has to be done for Player $B$, but with $R_A$ (current rating $A$) and $R_B$ (current rating $B$) swapped so that $E[A] + E[B] = 1$. Once the match is played and $S_A$ (actual outcome or score for Team $A$) and $S_B$ (actual outcome or score for Team $B$) are determined, $R^{\prime}_A$ (the new rating for $A$) and $R^{\prime}_B$ (the new rating for $A$) are calculated with the formula below:

$$
R^{\prime}_A=R_A+K(S_A-E[A])
$$

The $S$ value in our case would either be 1 for a win, or 0 for a loss. This is because there are no ties in the NBA.

In this equation, $K$ is an optimization constant that usually takes different values according the sport and the amount of games available. In other words, this value is the maximum amount by which a score can change in one match. If $K$ is set too high, the ratings will jump around too much; if $K$ is set too low, Elo will take too long to recognize important changes in team quality. Determining the right value of K is an entirely different and more complicated topic, so for this experiment we will be using $K=20$, the optimal $K$ for the NBA determined by FiveThirtyEight [3]. This is higher than most other sports and can likely be attributed to the fact that the NBA plays more games (81 games per team) and is subject to relatively little randomness.

Home-court advantage is set as equivalent to 100 Elo rating points. One hundred Elo points is equivalent to about 3.5 NBA points, so it can also be interpreted as the home team being favored by 3 to 4 points if the teams were otherwise evenly matched (obviously this value fluctuates from season to season). Since every team plays about half of their games at home and the other half away, a change in the home-court advantage value does not produce a significant difference in the ratings, but is still an important factor to consider.

Elo strikes a nice balance between ratings systems that account for margin of victory and those that do not. While teams always gain Elo points after wins and lose Elo points after losses, they also gain or lose more with larger margins of victory.

This works by assigning a multiplier to each game based on the final score and dividing it by a team’s projected margin of victory conditional upon having won the game. For instance, the Golden State Warriors' 4-point margin over the Houston Rockets in Game 1 of the 2018-19 Western Conference finals was lower than Elo would expect for a Warriors win. So the Warriors gain Elo points, but not as many as if they’d won by a larger margin. The formula accounts for diminishing returns; going from a 5-point win to a 10-point win matters more than going from a 25-point win to a 30-point win. For the exact formula, see the footnotes.

Instead of resetting each team’s rating when a new season begins, Elo carries over a portion of a team’s rating from one season to the next. This is to account for any momentum that a team may build from season-to-season (i.e. sports dynasties). In NBA ratings, three-quarters of the previous score are kept. The high fraction reflects the fact that NBA teams are more consistent from year to year. For example, the Miami Heat ended the 2012-13 NBA season with an Elo rating of 1754. The team’s Elo rating for the start of the 2013-14 season is calculated as follows:

$$
(0.75 * 1754) + (0.25 * 1500) = 1692
$$

Since this is a consistent method, we will also initialize the Elo scores for the 2019-20 NBA Season using the Elo scores from the 2018-19 season.

After incorporating a constant for home court advantage, our formula is as follows with $A=100$ points (the value we previously determined represents a home-court advantage):

$$
P(\mbox{Home team wins}) = \frac{1}{1 + 10^{-\frac{(H-R+A)}{400}}}
$$

```{r elo_logit, echo=FALSE, out.width='100%', fig.width = 8, fig.height = 5, fig.align='center', out.width='.49\\linewidth', fig.cap="\\label{fig:logit}Logistic Function of Win Probability by Elo Rating Difference", comment=NA, warning=FALSE}
include_graphics('./logistic.png')
```

In Figure \ref{fig:logit}, we see an example of a logistic function for win probability by Elo rating difference.

### Calculating Historic Elos

### Simulations

After calculating the elo ratings for each NBA team up until the last game they played (before the season was cancelled), we used these ratings to then perform simulations matching up teams based on the rest of the season that was supposed to happen, as well as the post-season tournaments based on the top performers of the regular season.

```{r, results='hide', echo=FALSE, warning=FALSE, error=FALSE, message=FALSE}
# Running simulations on the remaining regular season schedule, then for playoffs, then for finals
library(elo)
library(dplyr)

# Remainder of regular season
reg_season <- nba.remaining.games.2019.2020
str(reg_season)
head(reg_season)

reg_season$home_team <- as.character(reg_season$home_team)
reg_season$visitor_team <- as.character(reg_season$visitor_team)

elos <- nba.elo.current.2019.2020
head(elos, 30)

elos$team <- as.character(elos$team)
str(elos)

# DF to store elos after each game for plotting
elo_history = data.frame(teams = as.character(elos$team))
elo_history$elo = elos$elo

# List of winners
winners <- c()

matchups <- reg_season[2:3]
head(matchups)
str(matchups)


#row = 1 # For test purposes
for (row in 1:nrow(matchups)) {
  
  # Home Team and Away Team
  home <- matchups[row, "home_team"]
  away  <- matchups[row, "visitor_team"]
  
  # Pre-match ratings
  x = subset(elos, team == home)
  elo.A <- (as.integer(c(x[3])) + as.integer(10)) # plus 10/100 represents HCA
  
  y = subset(elos, team == away)
  elo.B <- as.integer(c(y[3]))
  
  # Probability of winning
  prob.A <- elo.prob(elo.A, elo.B)
  prob.B <- elo.prob(elo.B, elo.A)
  
  # Sample from distribution of size 1 because if repeated the team with higher score is obviously expected to win. this makes it more "random"
  winner <- sample(c(home, away), size=1, prob=c(prob.A, prob.B))
  
  # Add winner to list of winners for each matchup
  winners <- c(winners, winner)
  
  if (winner == home) {
    result = c(1)
  } else if (winner == away) {
    result = c(0)
  }
  
  # Let's update our ratings
  new_elo <- elo.calc(wins.A = result,
                      elo.A = elo.A, 
                      elo.B = elo.B, 
                      k = 20)
  
  # The results come back as a data.frame
  # with team A's new rating in row 1 / column 1
  # and team B's new rating in row 1 / column 2
  teamA_new_elo <- new_elo[1, 1]
  teamB_new_elo <- new_elo[1, 2]
  
  # We then update the ratings for teams A and B
  # and leave the other teams as they were
  elos <- elos %>%
    mutate(elo = if_else(team == home, teamA_new_elo,
                         if_else(team == away, teamB_new_elo, elo)))
  
  # Add updated elos to elo history (FIX THIS)
  elo_history[, paste(as.character("game"), as.character(row), sep="")] <- elos$elo
  
}

# After a few minutes, you should get a nice teams data.frame, with the most up-to-date international Elo ratings for June 2018
elos %>%
  arrange(-elo) %>%
  head(30)

# Add winners list to the schedule
reg_season$winners = winners
head(reg_season)

# Show Elo History
head(elo_history)

# Playoffs
# The top eight teams in each conference (East and West), ranked in order by win-loss records, qualify for the playoffs.
# Eastern Conference
'
EC <- c("Milwaukee Bucks", "Toronto Raptors", "Boston Celtics", "Miami Heat", "Indiana Pacers", "Philadelphia 76ers", "Brooklyn Nets", "Orlando Magic", 
        "Washington Wizards", "Charlotte Hornets", "Chicago Bulls", "New York Knicks", "Detroit Pistons", "Atlanta HAwks", "Cleveland Cavaliers")
# Western Conference
WC <- c("Los Angeles Lakers", "Los Angeles Clippers", "Denver Nuggets", "Utah Jazz", "Oklahoma City Thunder", "Houston Rockets", "Dallas Mavericks", "Memphis Grizzlies", 
        "Portland Trail Blazers", "New Orleans Pelicans", "Sacramento Kings", "San Antonio Spurs", "Phoenix Suns", "Minnesota Timberwolves", "Golden State Warriors")

eastern_conference = data.frame(team = EC, elo=0, stringsAsFactors = FALSE)
western_conference = data.frame(team = WC, elo=0, stringsAsFactors = FALSE)


for (row in 1:nrow(eastern_conference)) {
  team <- eastern_conference[row, "team"]
  elo  <- eastern_conference[row, "elo"]
  
  team_elo = subset(elos, team == team)
  elo = team_elo
}

for (row in 1:nrow(western_conference)) {
  team <- western_conference[row, "team"]
  elo  <- western_conference[row, "elo"]
  
  team_elo = subset(elos, team == team)
  elo = team_elo
}

# Top 8 in EC
eastern_conference %>%
  arrange(-elo) %>%
  head(8)

# Top 8 in WC
western_conference %>%
  arrange(-elo) %>%
  head(8)
'

# Different Way (TOP 8 TEAMS FROM EACH CONFERENCE)
WC_teams <- elos %>%
  filter(team %in% c("Los Angeles Lakers", "Los Angeles Clippers", "Denver Nuggets", "Utah Jazz", "Oklahoma City Thunder", "Houston Rockets", "Dallas Mavericks", "Memphis Grizzlies", 
                     "Portland Trail Blazers", "New Orleans Pelicans", "Sacramento Kings", "San Antonio Spurs", "Phoenix Suns", "Minnesota Timberwolves", "Golden State Warriors")) %>%
  arrange(-elo) %>%
  head(8)


EC_teams <- elos %>%
  filter(team %in% c("Milwaukee Bucks", "Toronto Raptors", "Boston Celtics", "Miami Heat", "Indiana Pacers", "Philadelphia 76ers", "Brooklyn Nets", "Orlando Magic", 
                     "Washington Wizards", "Charlotte Hornets", "Chicago Bulls", "New York Knicks", "Detroit Pistons", "Atlanta HAwks", "Cleveland Cavaliers")) %>%
  arrange(-elo) %>%
  head(8)

# Each team earns a spot on the playoff bracket, known as a “seed,” which will determine what team they will face off against.
# Seeding is based off of win/loss with ties becomign a bit more complicated through further evaluation
# For this project we will seeed based off of elo scores (very low probability of ties in scores). This also makes sense because elos are based on W/L.
# The conference DFs are already ordered by elo, so we can just put 1-8 as seed
WC_teams$seed <- c(1:8)

EC_teams$seed <- c(1:8)

# Technically there is a system in place designed for HCA in playoffs given to the team with the better record/higher seed
# Each NBA playoff series is composed of 4 to 7 games that are played in a 2-2-1-1-1 format. 
# This means that the team with the home-court advantage hosts games 1, 2, 5, and 7 while its opponent hosts games 3, 4, and 6, with games 5-7 only being played if necessary.
# However, because this complicates our implementation, we will ignore HCA for the playoffs and finals (although it does sometimes have an impact on the result)

# 1st Round - Playoffs (16 teams): Best-of-7 Series
# 1 vs 8, 2 vs 7, 3 vs 6, 4 vs 5
# Make dataframe for matchups
playoffs = data.frame(matrix(ncol = 2, nrow = 8))
colnames(playoffs) <- c("team1", "team2")

# Playoff Schedule
playoffs$team1 <- c(WC_teams[1,2], WC_teams[2,2], WC_teams[3,2], WC_teams[4,2], EC_teams[1,2], EC_teams[2,2], EC_teams[3,2], EC_teams[4,2])
playoffs$team2 <- c(WC_teams[8,2], WC_teams[7,2], WC_teams[6,2], WC_teams[5,2], EC_teams[8,2], EC_teams[7,2], EC_teams[6,2], EC_teams[5,2])

first_round <- c()
#row = 1 # For test purposes
#i = 1 # For test purposes
for (row in 1:nrow(playoffs)) {
  
  # Home Team and Away Team
  team1 <- playoffs[row, "team1"]
  team2  <- playoffs[row, "team2"]
  
  # For loop here? for i in 1:7
  series <- c()
  for (i in 1:7) {
    # Pre-match ratings
    x = subset(elos, team == team1)
    elo.A <- (as.integer(c(x[3])))
    
    y = subset(elos, team == team2)
    elo.B <- as.integer(c(y[3]))
    
    # Probability of winning
    prob.A <- elo.prob(elo.A, elo.B)
    prob.B <- elo.prob(elo.B, elo.A)
    
    # Best of 7 series sampling
    winner <- sample(c(team1, team2), size=1, prob=c(prob.A, prob.B), replace=TRUE) # size = 7?
    series <- c(series, winner)
    
    # Add winner to list of winners for each matchup
    #first_round <- c(first_round, winner)
    
    if (winner == team1) {
      result = c(1)
    } else if (winner == team2) {
      result = c(0)
    }
    
    # Let's update our ratings
    new_elo <- elo.calc(wins.A = result,
                        elo.A = elo.A, 
                        elo.B = elo.B, 
                        k = 20)
    
    # The results come back as a data.frame
    # with team A's new rating in row 1 / column 1
    # and team B's new rating in row 1 / column 2
    teamA_new_elo <- new_elo[1, 1]
    teamB_new_elo <- new_elo[1, 2]
    
    # We then update the ratings for teams A and B
    # and leave the other teams as they were
    elos <- elos %>%
      mutate(elo = if_else(team == team1, teamA_new_elo,
                           if_else(team == team2, teamB_new_elo, elo)))
    
    # Add updated elos to elo history
    elo_history[, paste(as.character("game"), as.character(row), sep="")] <- elos$elo
    
    # Check for best of 7
    team1_wins <- length(which(series == team1))
    team2_wins <- length(which(series == team2))
    if (team1_wins == 4) {
      first_round <- c(first_round, team1)
      break
    } else if (team2_wins == 4) {
      first_round <- c(first_round, team2)
      break
    }
  }
}

#elo_history
first_round


# 2nd Round - Conference Semifinals (8 Teams): Best-of-7 Series
semi = data.frame(matrix(ncol = 2, nrow = 4))
colnames(semi) <- c("team1", "team2")

# Playoff Schedule
# Western Conference ---- Eastern Conference
semi$team1 <- c(first_round[1], first_round[3], first_round[5], first_round[7])
semi$team2 <- c(first_round[2], first_round[4], first_round[6], first_round[8]) 

second_round <- c()
#row = 1 # For test purposes
#i = 1 # For test purposes
for (row in 1:nrow(semi)) {
  
  # Home Team and Away Team
  team1 <- semi[row, "team1"]
  team2  <- semi[row, "team2"]
  
  # For loop here? for i in 1:7
  series <- c()
  for (i in 1:7) {
    # Pre-match ratings
    x = subset(elos, team == team1)
    elo.A <- (as.integer(c(x[3])))
    
    y = subset(elos, team == team2)
    elo.B <- as.integer(c(y[3]))
    
    # Probability of winning
    prob.A <- elo.prob(elo.A, elo.B)
    prob.B <- elo.prob(elo.B, elo.A)
    
    # Best of 7 series sampling
    winner <- sample(c(team1, team2), size=1, prob=c(prob.A, prob.B), replace=TRUE) # size = 7?
    series <- c(series, winner)
    
    # Add winner to list of winners for each matchup
    #first_round <- c(first_round, winner)
    
    if (winner == team1) {
      result = c(1)
    } else if (winner == team2) {
      result = c(0)
    }
    
    # Let's update our ratings
    new_elo <- elo.calc(wins.A = result,
                        elo.A = elo.A, 
                        elo.B = elo.B, 
                        k = 20)
    
    # The results come back as a data.frame
    # with team A's new rating in row 1 / column 1
    # and team B's new rating in row 1 / column 2
    teamA_new_elo <- new_elo[1, 1]
    teamB_new_elo <- new_elo[1, 2]
    
    # We then update the ratings for teams A and B
    # and leave the other teams as they were
    elos <- elos %>%
      mutate(elo = if_else(team == team1, teamA_new_elo,
                           if_else(team == team2, teamB_new_elo, elo)))
    
    # Add updated elos to elo history
    elo_history[, paste(as.character("game"), as.character(row), sep="")] <- elos$elo
    
    # Check for best of 7
    team1_wins <- length(which(series == team1))
    team2_wins <- length(which(series == team2))
    if (team1_wins == 4) {
      second_round <- c(second_round, team1)
      break
    } else if (team2_wins == 4) {
      second_round <- c(second_round, team2)
      break
    }
  }
}

#elo_history
second_round

# 3rd Round - Conference Championships (4 Teams): Best-of-7 Series
# At the end of the playoffs, the top two teams play each other in the Conference Finals, to determine the Conference Champions from each side, who then proceed to play in the NBA Finals.
conference = data.frame(matrix(ncol = 2, nrow = 2))
colnames(conference) <- c("team1", "team2")

# Playoff Schedule
# Western Conference ---- Eastern Conference
conference$team1 <- c(second_round[1], second_round[3])
conference$team2 <- c(second_round[2], second_round[4]) 

third_round <- c()
#row = 1 # For test purposes
#i = 1 # For test purposes
for (row in 1:nrow(conference)) {
  
  # Home Team and Away Team
  team1 <- conference[row, "team1"]
  team2  <- conference[row, "team2"]
  
  # For loop here? for i in 1:7
  series <- c()
  for (i in 1:7) {
    # Pre-match ratings
    x = subset(elos, team == team1)
    elo.A <- (as.integer(c(x[3])))
    
    y = subset(elos, team == team2)
    elo.B <- as.integer(c(y[3]))
    
    # Probability of winning
    prob.A <- elo.prob(elo.A, elo.B)
    prob.B <- elo.prob(elo.B, elo.A)
    
    # Best of 7 series sampling
    winner <- sample(c(team1, team2), size=1, prob=c(prob.A, prob.B), replace=TRUE) # size = 7?
    series <- c(series, winner)
    
    # Add winner to list of winners for each matchup
    #first_round <- c(first_round, winner)
    
    if (winner == team1) {
      result = c(1)
    } else if (winner == team2) {
      result = c(0)
    }
    
    # Let's update our ratings
    new_elo <- elo.calc(wins.A = result,
                        elo.A = elo.A, 
                        elo.B = elo.B, 
                        k = 20)
    
    # The results come back as a data.frame
    # with team A's new rating in row 1 / column 1
    # and team B's new rating in row 1 / column 2
    teamA_new_elo <- new_elo[1, 1]
    teamB_new_elo <- new_elo[1, 2]
    
    # We then update the ratings for teams A and B
    # and leave the other teams as they were
    elos <- elos %>%
      mutate(elo = if_else(team == team1, teamA_new_elo,
                           if_else(team == team2, teamB_new_elo, elo)))
    
    # Add updated elos to elo history
    elo_history[, paste(as.character("game"), as.character(row), sep="")] <- elos$elo
    
    # Check for best of 7
    team1_wins <- length(which(series == team1))
    team2_wins <- length(which(series == team2))
    if (team1_wins == 4) {
      third_round <- c(third_round, team1)
      break
    } else if (team2_wins == 4) {
      third_round <- c(third_round, team2)
      break
    }
  }
}

#elo_history
third_round

# NBA Finals (7-Game Series)
finals = data.frame(matrix(ncol = 2, nrow = 1))
colnames(finals) <- c("team1", "team2")

# Playoff Schedule
# Western Conference ---- Eastern Conference
finals$team1 <- c(third_round[1])
finals$team2 <- c(third_round[2]) 

champion <- c()
#row = 1 # For test purposes
#i = 1 # For test purposes
for (row in 1:nrow(finals)) {
  
  # Home Team and Away Team
  team1 <- semi[row, "team1"]
  team2  <- semi[row, "team2"]
  
  # For loop here? for i in 1:7
  series <- c()
  for (i in 1:7) {
    # Pre-match ratings
    x = subset(elos, team == team1)
    elo.A <- (as.integer(c(x[3])))
    
    y = subset(elos, team == team2)
    elo.B <- as.integer(c(y[3]))
    
    # Probability of winning
    prob.A <- elo.prob(elo.A, elo.B)
    prob.B <- elo.prob(elo.B, elo.A)
    
    # Best of 7 series sampling
    winner <- sample(c(team1, team2), size=1, prob=c(prob.A, prob.B), replace=TRUE) # size = 7?
    series <- c(series, winner)
    
    # Add winner to list of winners for each matchup
    #first_round <- c(first_round, winner)
    
    if (winner == team1) {
      result = c(1)
    } else if (winner == team2) {
      result = c(0)
    }
    
    # Let's update our ratings
    new_elo <- elo.calc(wins.A = result,
                        elo.A = elo.A, 
                        elo.B = elo.B, 
                        k = 20)
    
    # The results come back as a data.frame
    # with team A's new rating in row 1 / column 1
    # and team B's new rating in row 1 / column 2
    teamA_new_elo <- new_elo[1, 1]
    teamB_new_elo <- new_elo[1, 2]
    
    # We then update the ratings for teams A and B
    # and leave the other teams as they were
    elos <- elos %>%
      mutate(elo = if_else(team == team1, teamA_new_elo,
                           if_else(team == team2, teamB_new_elo, elo)))
    
    # Add updated elos to elo history
    elo_history[, paste(as.character("game"), as.character(row), sep="")] <- elos$elo
    
    # Check for best of 7
    team1_wins <- length(which(series == team1))
    team2_wins <- length(which(series == team2))
    if (team1_wins == 4) {
      champion <- c(champion, team1)
      break
    } else if (team2_wins == 4) {
      champion <- c(champion, team2)
      break
    }
  }
}

#elo_history
# CHAMPION
champion

# All stages
first_round
second_round
third_round
champion

# Plot elo_history
library(reshape2)
library(ggplot2)

matplot(t(elo_history[,-c(1)]), type="l")

df_melted = melt(elo_history, id.vars='teams')

ggplot(df_melted, aes(x = variable, y = value)) + 
  geom_line(aes(color = teams, group = teams)) +
  theme(axis.text.x=element_blank(),
        axis.ticks.x=element_blank()) +
  ggtitle("End of Regular Season, Playoffs, & Finals") +
  xlab("Games") + ylab("Elo Rating")


# Drawbacks
# Best of 7 series do not account for HCA, too complicated to incorporate
# Simulation is random and you could get different outcomes (create a list and find most common answer?)
# Elo is based only off win/loss, HCA, margin, does not account for roster changes, injuries, and other factors
```

##### The Remaining 2019-2020 Regular Season

Since the 2019-2020 season was cancelled before the end of the regular season, there were still more games to be played. Fortunately, we were able to scrape the remaining schedule that includes all the games that were supposed to happen for the rest of the regular season. The schedule looked something like so:

```{r, echo=FALSE}
head(reg_season[1:6])
```

The regular season would have lasted all the way through April. Since we have all the matchups, we can run these teams through a simulation to compete based on probability using their elo ratings. This involved looping through the dataset, pulling each teams elo rating to calculate their probability of winning or losing, and then pulling a random sample as the winner. After the winner is found, the elo ratings are then updated to reflect this outcome.

To get an understanding of these results, we added the winners of each match to the dataframe next to each game.

```{r, echo=FALSE}
head(reg_season)
```

This finalized the regular season, resulting in the updated elo scores going into the playoffs.

```{r, echo=FALSE}
elos %>%
  arrange(-elo) %>%
  head(30)
```


##### The 2019-2020 NBA Playoffs

For the NBA playoffs, the top 8 teams in terms of win/loss record from each conference (Eastern Conference & Western Conference) advance to the playoffs. The teams are then seeded (ranked) based on these win/loss records, and matched accordingly for the playoffs. This means the #1 seed plays the #8 seed, the #2 seed plays the #7 seed, the the #3 seed plays the #6 seed, and the #4 seed plays the #5 seed, in each conference. Since the seedings are based on win/loss, we found it appropriate to seed the teams based on elo ratings (which is an outcome of win/loss). This also helps to avoid the complicated process should two teams have the same win loss record (there is a significantly lower probability two teams in this case have the exact same elo score). This is how the first round playoff matchups turned out:

```{r, echo=FALSE}
playoffs
```

The same process for the regular season was applied to these matchups with a couple of tweaks. For starters, this simulation was a best-of-7 tournament (as are all playoffs and finals matches). This means we had to simulate the games until a team reached 4 wins. The teams who won the right to advance to the second round are as follows:

```{r, echo=FALSE}
first_round
```

The second round is the same process as the first round, except this time, the top 4 teams of each conference advance, meaning that the other 4 finish their season early. The second round is also known as the conference semifinals, that is, the winners of these games advance to their respective conference finals to compete for the conference title. The second round matchups are shown below:

```{r, echo=FALSE}
semi
```

with the winners being:

```{r, echo=FALSE}
second_round
```

The last round of the playoffs is the third round, also referred to as the conference finals. The top two teams from both the western and eastern conference compete for the top spot in their respective conference. The winners that advanced from the second round are:

```{r. echo=FALSE}
conference
```

Again, these teams were put through a best-of-7 simulation, in whcih the following winners emerged:

```{r, echo=FALSE}
third_round
```

Finally, the NBA Finals. This is where the top winning teams from each conference (also the conference champions), compete head-to-head for the season. For our simu;ation, this turned out to be:

```{r, echo=FALSE}
finals
```

with the 2019-2020 NBA Champions being... *drum roll*...

```{r, echo=FALSE}
champion
```

##### End of Season Elo Ratings

After all is settled, the final elo ratings after the 2019-2020 NBA season turned out to be:

```{r, echo=FALSE}
elos
```

You can find visuals of how these elo ratings changed throughout this process in the results section of this report.

## Predicting the 2019-20 NBA Season Award Winners

Another interesting part of any NBA season is the awards given to the players and teams based on their regular season performances. Some key awards that catch headlines every year include Most Valuable Player (MVP) and Defensive Player of the Year (DPOY). In addition to predicting the end-of-season standings, we decided that any analysis of the remainder of the 2019-20 NBA season would be incomplete unless it discussed award winners in the major categories. As avid basketball fans, this idea resonated with us so we decided to scientifically predict who would ultimately win the MVP and DPOY awards.

In order to predict award winners at the end of the season, we needed to predict the leaders of some of the crucial statistical categories at the end of the season. To predict these players, we analyzed some significant statistics and identified the optimal regression model to predict these statistics. Some of the statistics we utilized in building this model include true shooting percentage (TS%), total rebound percentage (TRB%), assist percentage (AST%), and block percentage (BLK%) among 22 total recorded categories. For additional information on the exact statistics that were used in these predictions, refer to Table 3 (Appendix).

Accordingly, we examined different types of regression models in order to identify which type of model best predicted some of the major statistics. These include win shares (WS), value over replacement player (VORP), player efficiency rating (PER), usage percentage (USG%), offensive box plus/minus (OBPM), and defensive box plus/minus (DBPM). For more detailed explanations of the significance of each of these statistics, refer to Table 3 (Appendix).

To identify the best prediction model, we first predicted WS from the current 2019-20 season statistics using 4 different regression models: linear, lasso, ridge, and logistic. We measured the performance of every model with the actual WS values for each player using RMSE (root mean squared error) to determine which had the least error where smaller RMSE values indicated higher accuracy. In order to reduce Monte Carlo variability, we used 200 repeated random samples of the data for each model to find the true RMSE values.

We then used this to predict the MVP and DPOY by looking at the leaders at the end of the season in WS, VORP, PER, USG%, OBPM, and DBPM because these categories carried significant weighting in determing the respective awards. In order to produce statistics that would reflect the end-of-season data, we updated each player's stats based on their team, position, schedule matchups, and usage percentage. We weighted each of these features by category and used the current player statistics to simulate the expected statistics for every player at the end of the 2019-20 season. We chose these specific features because a player's team and schedule can heavily influence their output, the position they play directly affects which stats are affected, and their usage percentage indicates how heavily their team relies on that specific player (which correlates to more playing time). For example, a point guard is more likely to focus on assists, a shooting guard is more likely to focus on shooting percentage and 3-point attempt percentage, and a center is more likely to focus on rebounds and blocks. Similarly, a player with a high usage percentage will be instrumental to the team and will thus receive more playing time to add to their stat lines.

Another important note to consider is that some of the statistical categories are related to other categories. For example, offensive win shares (OWS) and defensive win shares (DWS) are directly related to overall win shares (WS) because they are simply more specific aspects of the general WS category. In order to account for these confounding variables and ensure that the predictions were accurately estimated from all of the relevant data, we made sure to exclude the respective confounding variables when running each regression model. For instance, we excluded BPM when running regression models on OBPM and DBPM for the same reason.


```{r calculate_elo, include=FALSE}
nbateams <- data.frame(team=union(season2019_2020$home_team_name, season2019_2020$visitor_team_name))
nbateams <- nbateams %>% mutate(elo=1500)
nbateams

historical_elo <- data.frame(team = nbateams$team)
historical_elo <- historical_elo %>% mutate(elo=1500)

head(season2019_2020)
season2019_2020$home_team_wins

#Copy and paste season data.frame into loop (seq and match) to update elo for consecutive seasons
for (i in seq(nrow(season2019_2020))) {
  match <- season2019_2020[i, ]
  
  #Pre-match ratings
  teamA_elo <- subset(nbateams, team==match$home_team_name)$elo
  teamB_elo <- subset(nbateams, team==match$visitor_team_name)$elo
  
  #Update our ratings
  new_elo <- elo.calc(wins.A = match$home_team_wins,
                      elo.A = teamA_elo,
                      elo.B = teamB_elo,
                      k = 20)
  
  #Results reported as data.frame
  #Team A's new rating in row1/column1
  #Team B's new rating in row1/column2
  new_elo
  teamA_new_elo <- new_elo[1,1]
  teamB_new_elo <- new_elo[1,2]
  
  #Update the ratings for Teams A and B and leave other teams as they were
  nbateams <- nbateams %>%
    mutate(elo = if_else(team==match$home_team_name, teamA_new_elo,
                         if_else(team==match$visitor_team_name, teamB_new_elo, elo)))
}

options(digits=8)

nbateams %>%
  arrange(-elo)

avg_season_elo = 1505

nbateams <- nbateams %>% mutate(elo=0.75*elo+.25*avg_season_elo)

nbateams <- nbateams %>%
  arrange(-elo)

names(nbateams)[names(nbateams) == "team"] <- "Team"
names(nbateams)[names(nbateams) == "elo"] <- "Elo Rating"
```

```{r elo_ratings, fig.pos = "H", echo=FALSE, comment=NA}
kable(list(nbateams[1:15,], nbateams[16:30,]), caption = "Elo Ratings for Every NBA Team (Descending)")
```

```{r regression_models, include=FALSE}
player_stats <- data.frame(player_stats)
player_stats <- player_stats[!(player_stats$Tm=="TOT"),]
player_stats <- player_stats[(player_stats$G>=25 & player_stats$MP>=1200),]


# rmse function
rmse = function(y, yhat) {
  sqrt(mean((y - yhat)^2, na.rm=TRUE))
}

# variables that control how long the program takes to run
num_splits = 200
#k_limit = 20

#model 1: linear regression model (RMSE)
#80% training data, 20% test data
n = nrow(player_stats)
n_train = round(0.8*n)  # round to nearest integer
n_test = n - n_train

#200 different random splits
lm_vals = do(num_splits)*{
  
  # re-split into train and test cases with the same sample sizes
  train_cases = sample.int(n, n_train, replace=FALSE)
  test_cases = setdiff(1:n, train_cases)
  on_train = player_stats[train_cases, 6:27]
  on_test = player_stats[test_cases, 6:27]
  
  linearModel = lm(WS ~ (. - WS.48 - OWS - DWS), data=on_train)
  linearModelInteractions = lm(WS ~ (. - WS.48 - OWS - DWS)^2, data=on_train)
  
  # Predictions out of sample + convert to binary
  y_test = predict(linearModel, on_test)
  y_test_2 = predict(linearModelInteractions, on_test)
  
  c(rmse(y_test, on_test$WS),rmse(y_test_2, on_test$WS))
}
lm_avg = unname(colMeans(lm_vals))
lm_avg


#models 2,3: lasso regression/ridge regression (RMSE)
vals_lr_rr = do(num_splits)*{
  
  # re-split into train and test cases with the same sample sizes
  train_cases = sample.int(n, n_train, replace=FALSE)
  test_cases = setdiff(1:n, train_cases)
  on_train = player_stats[train_cases, 6:27]
  on_test = player_stats[test_cases, 6:27]
  
  temp_train = model.matrix.lm(WS ~ (. - WS.48 - OWS - DWS), data = on_train, na.action=na.pass)
  temp_test = model.matrix.lm(WS ~ (. - WS.48 - OWS - DWS), data = on_test, na.action=na.pass)
  x_train = temp_train[complete.cases(temp_train),]
  y_train = on_train$WS[complete.cases(temp_train)]
  x_test = temp_test[complete.cases(temp_test),]
  y_test = on_test$WS[complete.cases(temp_test)]
  
  # lasso regression
  cv_fit_l = cv.glmnet(x_train, y_train, family="gaussian", alpha = 1)
  # ridge regression
  cv_fit_r = cv.glmnet(x_train, y_train, family="gaussian", alpha = 0)
  
  opt_lambda_l = cv_fit_l$lambda.min
  opt_lambda_r = cv_fit_r$lambda.min
  
  y_pred_l = predict(cv_fit_l$glmnet.fit, s = opt_lambda_l, newx = x_test)
  y_pred_r = predict(cv_fit_r$glmnet.fit, s = opt_lambda_r, newx = x_test)
  
  c(rmse(y_pred_l, y_test), rmse(y_pred_r, y_test))
}
lr_model_avg = min(vals_lr_rr[,1])
rr_model_avg = min(vals_lr_rr[,2])
lr_model_avg
rr_model_avg


#model 4: logistic regression
vals_logm = do(num_splits)*{
  # re-split into train and test cases with the same sample sizes
  train_cases = sample.int(n, n_train, replace=FALSE)
  test_cases = setdiff(1:n, train_cases)
  on_train = player_stats[train_cases, 6:27]
  on_test = player_stats[test_cases, 6:27]
  
  logitModel = glm(WS ~ (. - WS.48 - OWS - DWS), data=on_train, family=gaussian, maxit = 100)
  logitModelInteractions = glm(WS ~ (. - WS.48 - OWS - DWS)^2, data=on_train, family=gaussian, maxit = 100)
  
  # Predictions out of sample + convert to binary
  y_test = predict(logitModel, on_test)
  y_test_2 = predict(logitModelInteractions, on_test)
  
  c(rmse(y_test, on_test$WS), rmse(y_test_2, on_test$WS))
}
logm_vals = unname(colMeans(vals_logm))
```

```{r reg_model_rmse, include=FALSE, comment=NA, warning=NA}
cat("MODEL SUCCESS:")
cat("1) LINEAR REGRESSION MODEL (without interactions) - RMSE:", lm_avg[1])
cat("1) LINEAR REGRESSION MODEL (with interactions) - RMSE:", lm_avg[2])
cat("2) LASSO REGRESSION - RMSE:", lr_model_avg[1])
print("coefficients for lasso regression:")
print(coef(cv_fit_l$glmnet.fit,s = cv_fit_l$lambda.min))
cat("3) RIDGE REGRESSION - RMSE:", rr_model_avg[1])
#print("coefficients for ridge regression:")
#print(coef(cv_fit_r$glmnet.fit,s = cv_fit_r$lambda.min))
cat("4) LOGISTIC REGRESSION (without interactions) - RMSE:", logm_vals[1])
cat("4) LOGISTIC REGRESSION (with interactions) - RMSE:", logm_vals[2])
```

```{r pred_stat_leaders, echo=FALSE, fig.align='center', fig.cap="\\label{fig:pred_stat_leaders}End-of-Season Predicted Stat Leaders with Logistic Regression Model", fig.height=2, fig.show='hold', fig.width=3, warning=FALSE, comment=NA, out.width='.49\\linewidth'}
# Update player stats for end-of-season 2019-20

player_stats_update <- data.frame(player_stats)

player_stats_update$AST.[player_stats_update$Pos=="PG"] <- player_stats_update$AST.[player_stats_update$Pos=="PG"] + 0.5
player_stats_update$AST.[player_stats_update$Pos=="SG"] <- player_stats_update$AST.[player_stats_update$Pos=="SG"] + 0.1
player_stats_update$AST.[player_stats_update$Pos=="SF"] <- player_stats_update$AST.[player_stats_update$Pos=="SF"] - 0.1
player_stats_update$AST.[player_stats_update$Pos=="PF"] <- player_stats_update$AST.[player_stats_update$Pos=="PF"] + 0.2
player_stats_update$AST.[player_stats_update$Pos=="C"] <- player_stats_update$AST.[player_stats_update$Pos=="C"] - 0.2

player_stats_update$ORB.[player_stats_update$Pos=="PG"] <- player_stats_update$ORB.[player_stats_update$Pos=="PG"] - 0.1
player_stats_update$ORB.[player_stats_update$Pos=="SG"] <- player_stats_update$ORB.[player_stats_update$Pos=="SG"] - 0.1
player_stats_update$ORB.[player_stats_update$Pos=="SF"] <- player_stats_update$ORB.[player_stats_update$Pos=="SF"] + 0.3
player_stats_update$ORB.[player_stats_update$Pos=="PF"] <- player_stats_update$ORB.[player_stats_update$Pos=="PF"] + 0.5
player_stats_update$ORB.[player_stats_update$Pos=="C"] <- player_stats_update$ORB.[player_stats_update$Pos=="C"] + 0.7

player_stats_update$DRB.[player_stats_update$Pos=="PG"] <- player_stats_update$DRB.[player_stats_update$Pos=="PG"] - 0.1
player_stats_update$DRB.[player_stats_update$Pos=="SG"] <- player_stats_update$DRB.[player_stats_update$Pos=="SG"] - 0.1
player_stats_update$DRB.[player_stats_update$Pos=="SF"] <- player_stats_update$DRB.[player_stats_update$Pos=="SF"] + 0.3
player_stats_update$DRB.[player_stats_update$Pos=="PF"] <- player_stats_update$DRB.[player_stats_update$Pos=="PF"] + 0.5
player_stats_update$DRB.[player_stats_update$Pos=="C"] <- player_stats_update$DRB.[player_stats_update$Pos=="C"] + 0.7

player_stats_update$TRB.[player_stats_update$Pos=="PG"] <- player_stats_update$TRB.[player_stats_update$Pos=="PG"] - 0.2
player_stats_update$TRB.[player_stats_update$Pos=="SG"] <- player_stats_update$TRB.[player_stats_update$Pos=="SG"] - 0.2
player_stats_update$TRB.[player_stats_update$Pos=="SF"] <- player_stats_update$TRB.[player_stats_update$Pos=="SF"] + 0.4
player_stats_update$TRB.[player_stats_update$Pos=="PF"] <- player_stats_update$TRB.[player_stats_update$Pos=="PF"] + 0.6
player_stats_update$TRB.[player_stats_update$Pos=="C"] <- player_stats_update$TRB.[player_stats_update$Pos=="C"] + 0.8

player_stats_update$BLK.[player_stats_update$Pos=="PG"] <- player_stats_update$BLK.[player_stats_update$Pos=="PG"] - 0.2
player_stats_update$BLK.[player_stats_update$Pos=="SG"] <- player_stats_update$BLK.[player_stats_update$Pos=="SG"] - 0.2
player_stats_update$BLK.[player_stats_update$Pos=="SF"] <- player_stats_update$BLK.[player_stats_update$Pos=="SF"] + 0.2
player_stats_update$BLK.[player_stats_update$Pos=="PF"] <- player_stats_update$BLK.[player_stats_update$Pos=="PF"] + 0.3
player_stats_update$BLK.[player_stats_update$Pos=="C"] <- player_stats_update$BLK.[player_stats_update$Pos=="C"] + 0.5

player_stats_update$TS.[player_stats_update$Pos=="PG"] <- player_stats_update$TS.[player_stats_update$Pos=="PG"] + 0.01
player_stats_update$TS.[player_stats_update$Pos=="SG"] <- player_stats_update$TS.[player_stats_update$Pos=="SG"] + 0.02
player_stats_update$TS.[player_stats_update$Pos=="SF"] <- player_stats_update$TS.[player_stats_update$Pos=="SF"] + 0.02
player_stats_update$TS.[player_stats_update$Pos=="PF"] <- player_stats_update$TS.[player_stats_update$Pos=="PF"] + 0.01
player_stats_update$TS.[player_stats_update$Pos=="C"] <- player_stats_update$TS.[player_stats_update$Pos=="C"] + 0.02


player_stats_update$WS[player_stats_update$Tm=="MIL"] <- player_stats_update$WS[player_stats_update$Tm=="MIL"] + 0.4
player_stats_update$WS[player_stats_update$Tm=="LAL"] <- player_stats_update$WS[player_stats_update$Tm=="LAL"] + 0.4
player_stats_update$WS[player_stats_update$Tm=="TOR"] <- player_stats_update$WS[player_stats_update$Tm=="TOR"] + 0.3
player_stats_update$WS[player_stats_update$Tm=="LAC"] <- player_stats_update$WS[player_stats_update$Tm=="LAC"] + 0.25
player_stats_update$WS[player_stats_update$Tm=="OKC"] <- player_stats_update$WS[player_stats_update$Tm=="OKC"] + 0.2


player_stats_update$WS[player_stats_update$USG.>=25.0] <- player_stats_update$WS[player_stats_update$USG.>=25.0] + 1.5
player_stats_update$WS.48[player_stats_update$USG.>=25.0] <- player_stats_update$WS.48[player_stats_update$USG.>=25.0] + 0.015



# Re-sample train/test splits
train_cases = sample.int(n, n_train, replace=FALSE)
test_cases = setdiff(1:n, train_cases)
on_train = player_stats_update[train_cases, 6:27]
on_test = player_stats_update[test_cases, 6:27]




logitModelWS = glm(WS ~ (. - WS.48 - OWS - DWS), data=on_train, family=gaussian, maxit = 100)

predicted_WS = predict(logitModelWS, player_stats_update[,6:27])

predictions_WS <- data.frame(player_stats_update$Player, predicted_WS)
predictions_WS <- predictions_WS %>%
  arrange(-predicted_WS)
#head(predictions_WS)

names(predictions_WS)[names(predictions_WS) == "player_stats_update.Player"] <- "Player"
names(predictions_WS)[names(predictions_WS) == "predicted_WS"] <- "Predicted WS"

#kable(predictions_WS[1:5,], caption = "Predicted WS Leaders at the End of the Regular Season")




logitModelVORP = glm(VORP ~ (. - WS - WS.48 - OWS - DWS), data=on_train, family=gaussian, maxit = 100)

predicted_VORP = predict(logitModelVORP, player_stats_update[,6:27])

predictions_VORP <- data.frame(player_stats_update$Player, predicted_VORP)
predictions_VORP <- predictions_VORP %>%
  arrange(-predicted_VORP)
#head(predictions_VORP)

names(predictions_VORP)[names(predictions_VORP) == "player_stats_update.Player"] <- "Player"
names(predictions_VORP)[names(predictions_VORP) == "predicted_VORP"] <- "Predicted VORP"

#kable(predictions_VORP[1:5,], caption = "Predicted VORP Leaders at the End of the Regular Season")




logitModelPER = glm(PER ~ (. - WS - WS.48 - OWS - DWS), data=on_train, family=gaussian, maxit = 100)

predicted_PER = predict(logitModelPER, player_stats_update[,6:27])

predictions_PER <- data.frame(player_stats_update$Player, predicted_PER)
predictions_PER <- predictions_PER %>%
  arrange(-predicted_PER)
#head(predictions_PER)

names(predictions_PER)[names(predictions_PER) == "player_stats_update.Player"] <- "Player"
names(predictions_PER)[names(predictions_PER) == "predicted_PER"] <- "Predicted PER"

#kable(predictions_PER[1:5,], caption = "Predicted PER Leaders at the End of the Regular Season")




logitModelUSG = glm(USG. ~ (. - WS - WS.48 - OWS - DWS), data=on_train, family=gaussian, maxit = 100)

predicted_USG = predict(logitModelUSG, player_stats_update[,6:27])

predictions_USG <- data.frame(player_stats_update$Player, predicted_USG)
predictions_USG <- predictions_USG %>%
  arrange(-predicted_USG)
#head(predictions_USG)

names(predictions_USG)[names(predictions_USG) == "player_stats_update.Player"] <- "Player"
names(predictions_USG)[names(predictions_USG) == "predicted_USG"] <- "Predicted USG%"

#kable(predictions_USG[1:5,], caption = "Predicted USG% Leaders at the End of the Regular Season")




logitModelOBPM = glm(OBPM ~ (. - WS - WS.48 - OWS - DWS - BPM), data=on_train, family=gaussian, maxit = 100)

predicted_OBPM = predict(logitModelOBPM, player_stats_update[,6:27])

predictions_OBPM <- data.frame(player_stats_update$Player, predicted_OBPM)
predictions_OBPM <- predictions_OBPM %>%
  arrange(-predicted_OBPM)
#head(predictions_OBPM)

names(predictions_OBPM)[names(predictions_OBPM) == "player_stats_update.Player"] <- "Player"
names(predictions_OBPM)[names(predictions_OBPM) == "predicted_OBPM"] <- "Predicted OBPM"

#kable(predictions_OBPM[1:5,], caption = "Predicted OBPM Leaders at the End of the Regular Season")




logitModelDBPM = glm(DBPM ~ (. - WS - WS.48 - OWS - DWS - BPM), data=on_train, family=gaussian, maxit = 100)

predicted_DBPM = predict(logitModelDBPM, player_stats_update[,6:27])

predictions_DBPM <- data.frame(player_stats_update$Player, predicted_DBPM)
predictions_DBPM <- predictions_DBPM %>%
  arrange(-predicted_DBPM)
#head(predictions_DBPM)

names(predictions_DBPM)[names(predictions_DBPM) == "player_stats_update.Player"] <- "Player"
names(predictions_DBPM)[names(predictions_DBPM) == "predicted_DBPM"] <- "Predicted DBPM"

#kable(predictions_DBPM[1:5,], caption = "Predicted DBPM Leaders at the End of the Regular Season")


kable(list(predictions_WS[1:5,], predictions_VORP[1:5,], predictions_PER[1:5,], predictions_USG[1:5,], predictions_OBPM[1:5,], predictions_DBPM[1:5,]), caption = "End-of-Season 2019-20 Predicted Stat Leaders with Logistic Regression Model")
```

# Results


**[Tables, figures, and text that illustrate your findings. Keep the focus on the numbers here. You will interpret your results in the next section.]**



First, we calculated the Elo ratings for each team for the games played so far in the 2019-20 season. As explained earlier, we incorporated 25% of the previous season's Elo ratings with 75% of this season's current Elo ratings. Table 1 shows the Elo ratings we derived for each team when the NBA season was suspended. To better visualize how each team's Elo rating is updated throughout the season, Figure ... shows the Elo rating of every team since the opening of the 2019-20 season for all games that have been played (prior to the suspension). ... **[NEED TO WRITE ABOUT ELO PREDICTIONS AND PLAYOFFS/FINALS HERE]**

A summary of the results of the simulation can be found below in the order of First Round Playoffs (top 8 teams from both conferences), Second Round Playoffs (top 4 teams from each conference), Third Round Playoffs (The conference finals), then the NBA Finals which produces the Seasons Champion. This will show who played, then who, out of those teams, won the right to move forward.

```{r, echo=FALSE}
# First Round
playoffs
first_round
# Second Round
semi
second_round
# Third Round
conference
third_round
# NBA Finals
finals
champion
```

The plot below shows how the Elo Ratings for each NBA team changed throughout the end of the regular season, as well as both the playoffs and finals. A line that remains flat for a short period of time represetns the Elo Rating reamining constant due to the fact of not playing at that instance. The changes come after they have played a game.

```{r, echo=FALSE}
# Plot elo_history
library(reshape2)
library(ggplot2)

#matplot(t(elo_history[,-c(1)]), type="l")

df_melted = melt(elo_history, id.vars='teams')

ggplot(df_melted, aes(x = variable, y = value)) + 
  geom_line(aes(color = teams, group = teams)) +
  theme(axis.text.x=element_blank(),
        axis.ticks.x=element_blank()) +
  ggtitle("End of Regular Season, Playoffs, & Finals") +
  xlab("Games") + ylab("Elo Rating")
```


In addition to simulating how the 2019-20 NBA season and Playoffs would have ended, we tested several regression models to determine the best model to predict end-of-season WS. By testing linear, lasso, ridge, and logistic regression models, found that the lasso model provided the lowest RMSE value (`r lr_model_avg[1]`) with the linear model (`r lm_avg[1]`) and logistic models (`r logm_vals[1]`) providing slightly higher RMSE values.

We then predicted the season leaders for the various principal categories of WS, VORP, PER, OBPM, and DBPM. We utilized a logistic regression model for predicting the stat leaders due to its relative simplicity and clarity. We verified that this logistic regression model was appropriate by measuring its RMSE values and plotting predicted end-of-season statistics for each player for every category as well as the actual vs. predicted statistics for each category for the current 2019-20 season data (Figure \ref{fig:pred_stat_plots}). The plots in Figure \ref{fig:pred_stat_plots} indicate the end-of-season statistic value for each category based on a player's current 2019-20 season data for that statistic. The red lines indicate the value that a player can expect to end the season with for every value along the x-axis (which represents the player's current statistic for that category). These plots verify that the predicted stats fall within a very small margin of the actual stats and thus have small residual values (since a majority of this season's games have already been played). Also, there is a very minor shift in some of the data points (i.e. VORP) because the last month of games would likely change some of these player statistics since teams with guaranteed playoff seeding are more likely to rest their star players.

Using these accumulated season statistics, we determined the end-of-season statistics by updating each players' stat lines based on team, position, schedule matchups, and usage percentage stats as explained in detail in the Methods section.

The final season stat leaders for each of the categories is shown in Table 2. We verified these predictions by limiting the qualifiers for each category and comparing with each player's previous performance history. We narrowed the pool of players down by only considering players with more than 25 games played and 1200 minutes played because this reflects the criteria that the NBA Season Awards use to nominate qualifying players. By inspecting the top five players in each category, we noticed several household names and early season favorites for MVP and DPOY including Giannis Antetokounmpo, James Harden, LeBron James, and Anthony Davis.

```{r echo=FALSE, fig.width = 5, fig.height = 3, fig.align='center', out.width='.49\\linewidth', fig.show='hold', fig.cap="\\label{fig:pred_stat_plots}Predictions of Key Statistics with Logistic Regression Model", fig.pos = "H", comment=NA, warning=FALSE}
ggplot() +
  geom_point(data=player_stats_update[,6:27],aes(x = WS, y = predicted_WS ), color="black") + 
  geom_line(data=player_stats[,6:27],aes(x = WS, y = WS ), color="red") + 
  xlab("Actual WS") + 
  ylab("Predicted WS") + 
  ggtitle("Actual WS vs. Predicted WS")

ggplot() +
  geom_point(data=player_stats_update[,6:27],aes(x = VORP, y = predicted_VORP ), color="black") + 
  geom_line(data=player_stats[,6:27],aes(x = VORP, y = VORP ), color="red") + 
  xlab("Actual VORP") + 
  ylab("Predicted VORP") + 
  ggtitle("Actual VORP vs. Predicted VORP")

ggplot() +
  geom_point(data=player_stats_update[,6:27],aes(x = PER, y = predicted_PER ), color="black") + 
  geom_line(data=player_stats[,6:27],aes(x = PER, y = PER ), color="red") + 
  xlab("Actual PER") + 
  ylab("Predicted PER") + 
  ggtitle("Actual PER vs. Predicted PER")

ggplot() +
  geom_point(data=player_stats_update[,6:27],aes(x = USG., y = predicted_USG ), color="black") + 
  geom_line(data=player_stats[,6:27],aes(x = USG., y = USG. ), color="red") + 
  xlab("Actual USG%") + 
  ylab("Predicted USG%") + 
  ggtitle("Actual USG% vs. Predicted USG%")

ggplot() +
  geom_point(data=player_stats_update[,6:27],aes(x = OBPM, y = predicted_OBPM ), color="black") + 
  geom_line(data=player_stats[,6:27],aes(x = OBPM, y = OBPM ), color="red") + 
  xlab("Actual OBPM") + 
  ylab("Predicted OBPM") + 
  ggtitle("Actual OBPM vs. Predicted OBPM")

ggplot() +
  geom_point(data=player_stats_update[,6:27],aes(x = DBPM, y = predicted_DBPM ), color="black") + 
  geom_line(data=player_stats[,6:27],aes(x = DBPM, y = DBPM ), color="red") + 
  xlab("Actual DBPM") + 
  ylab("Predicted DBPM") + 
  ggtitle("Actual DBPM vs. Predicted DBPM")
```



# Conclusion

**[Interpret what you found. What are the main lessons we should take away from your report?]**

Congratulations to the `r champion` on hypothetically winning the 2019-2020 NBA season, There were many great teams this year with a lot of tough matchups. Unfortunately, this year it was not the Houston Rockets.


## Drawbacks of the Elo Rating Predictions

Although elo ratings are simple and intuitive, this is both a blessing and a curse. Given the performance, ELo Rating should be commended, however, this does not mean it should be used to support that addictive sports gambling habit of yours. This method is designed to be effective despite its simplicity. This model does not account for roster changes, injusry updates, or individual player performance as most sports prediction models should. It evaluates the teams as a whole, solely based on win/loss, margin of victory, and home court advantage. Also, the simulations are random, based on a teams probability of winning. This means the results could vary each time you run it, which requires running it a reasonable amount of times (ast least 100) in order to get meaningful results. The results produced above are based on the simulation that ran when this document was created. However, after running it multiple times, the consistent winner of the 2019-2020 season proved to be the Los Angeles Lakers (RIP Kobe Bryant). This can be done by wrapping the script in a do loop that runs it 100 times while keeping track of the winner each season, and counting each teams wins to find who won most often. This method was used to get the result for the Los Angeles Lakers, but is not shown within this report.


# Appendix

```{r echo=FALSE, out.width='100%', fig.width = 8, fig.height = 5, fig.align='center', out.width='.49\\linewidth', fig.cap="\\label{fig:elo_chart}Breakdown of Elo Rating", comment=NA, warning=FALSE}
include_graphics('./EloChart.png')
```

```{r echo=FALSE, out.width='100%', fig.width = 8, fig.height = 5, fig.align='center', out.width='.49\\linewidth', fig.cap="\\label{fig:stat_chart}Statistics Recorded by NBA", comment=NA, warning=FALSE}
recorded_stats <- data.frame(colnames(player_stats[,6:27]))
names(recorded_stats)[1] <- "Statistics"
recorded_stats["Meaning"] <- c("Num. games played", 
                               "Num. minutes played", 
                               "Measure of per-minute production", 
                               "Overall shooting efficiency", 
                               "% of field goal attempts from 3-point range", 
                               "Num. free throw attempts per field goal attempt", 
                               "% of available offensive rebounds that a player grabbed", 
                               "% of available defensive rebounds that a player grabbed", 
                               "% of available total rebounds that a player grabbed", 
                               "% of teammate field goals that a player assisted", 
                               "% of opponent possessions that were stolen by a player", 
                               "% of opponent field goals attempts that were blocked by a player", 
                               "Num. turnovers committed per 100 plays", 
                               "% of team plays used by a player", 
                               "Num. wins contributed by a player from his offense", 
                               "Num. wins contributed by a player from his defense", 
                               "Num. wins contributed by a player", 
                               "Num. wins contributed by a player per 48 minutes", 
                               "Offensive points per 100 possessions above a league-average player", 
                               "Defensive points per 100 possessions above a league-average player", 
                               "Total points per 100 possessions above a league-average player", 
                               "Points per 100 team possessions contributed by a player above a replacement-level player")
kable(recorded_stats)
```

# References

> [1] List of all sporting events canceled around the world during the coronavirus pandemic (https://www.espn.com/olympics/story/_/id/28824781/list-sporting-events-canceled-coronavirus)


> [2] Elo ratings system (https://en.wikipedia.org/wiki/Elo_rating_system)


> [3] FiveThirtyEight NBA Elo Ratings (https://fivethirtyeight.com/features/how-we-calculate-nba-elo-ratings/)


> [4] Compilation of in-depth NBA statistics (https://www.basketball-reference.com/)


> [5] Elo Ratings for NBA Teams (http://practicallypredictable.com/2018/04/15/elo-ratings-for-nba-teams/#more-1019)